{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-12-04T06:08:34.843008Z","iopub.status.busy":"2025-12-04T06:08:34.842511Z","iopub.status.idle":"2025-12-04T06:08:34.850162Z","shell.execute_reply":"2025-12-04T06:08:34.848868Z","shell.execute_reply.started":"2025-12-04T06:08:34.842979Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2025-12-04T06:08:34.852135Z","iopub.status.busy":"2025-12-04T06:08:34.851796Z","iopub.status.idle":"2025-12-04T06:08:34.876008Z","shell.execute_reply":"2025-12-04T06:08:34.874844Z","shell.execute_reply.started":"2025-12-04T06:08:34.852108Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","A module that was compiled using NumPy 1.x cannot be run in\n","NumPy 2.3.3 as it may crash. To support both 1.x and 2.x\n","versions of NumPy, modules must be compiled with NumPy 2.0.\n","Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n","\n","If you are a user of the module, the easiest solution will be to\n","downgrade to 'numpy<2' or try to upgrade the affected module.\n","We expect that some modules will need time to support NumPy 2.\n","\n","Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n","  File \"<frozen runpy>\", line 88, in _run_code\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n","    app.launch_new_instance()\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n","    self.io_loop.start()\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n","    self.asyncio_loop.run_forever()\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n","    self._run_once()\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n","    handle._run()\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n","    await self.process_one()\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n","    await dispatch(*args)\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n","    await result\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n","    reply_content = await reply_content\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n","    res = shell.run_cell(\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n","    return super().run_cell(*args, **kwargs)\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n","    result = self._run_cell(\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n","    result = runner(coro)\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n","    if await self.run_code(code, result, async_=asy):\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"C:\\Users\\cgambar1\\AppData\\Local\\Temp\\ipykernel_32668\\3404545088.py\", line 7, in <module>\n","    import matplotlib.pyplot as plt\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py\", line 129, in <module>\n","    from . import _api, _version, cbook, _docstring, rcsetup\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py\", line 27, in <module>\n","    from matplotlib.colors import Colormap, is_color_like\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py\", line 56, in <module>\n","    from matplotlib import _api, _cm, cbook, scale\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\scale.py\", line 22, in <module>\n","    from matplotlib.ticker import (\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\ticker.py\", line 138, in <module>\n","    from matplotlib import transforms as mtransforms\n","  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 49, in <module>\n","    from matplotlib._path import (\n"]},{"ename":"AttributeError","evalue":"_ARRAY_API not found","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"]},{"ename":"ImportError","evalue":"numpy.core.multiarray failed to import","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Point, box\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:129\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py:56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\scale.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[0;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[0;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\ticker.py:138\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[0;32m    140\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    142\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    143\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    144\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    151\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsinhLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\transforms.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     53\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"]}],"source":["# IMPORTS AND SETUP\n","# Run this cell first to import all required libraries\n","\n","import pandas as pd\n","import numpy as np\n","import geopandas as gpd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from shapely.geometry import Point, box\n","from io import BytesIO\n","from datetime import datetime\n","import json\n","from ipywidgets import (FileUpload, Dropdown, Button, Output, VBox, HBox, \n","                        Text, Layout, HTML, Tab, Textarea, Checkbox)\n","from IPython.display import display, clear_output\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"‚úÖ All libraries imported successfully!\")\n","print(\"Ready to run the application.\")"]},{"cell_type":"code","execution_count":199,"metadata":{"execution":{"iopub.execute_input":"2025-12-04T06:08:34.878008Z","iopub.status.busy":"2025-12-04T06:08:34.877658Z","iopub.status.idle":"2025-12-04T06:08:34.920089Z","shell.execute_reply":"2025-12-04T06:08:34.918614Z","shell.execute_reply.started":"2025-12-04T06:08:34.877976Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ Global variables and output widgets initialized!\n"]}],"source":["# GLOBAL VARIABLES AND OUTPUT WIDGETS\n","# Initialize global variables and output panels\n","\n","# Global data storage\n","df = None\n","gdf = None\n","test_results = []\n","analysis_results = {}\n","\n","# Create output widgets for different panels\n","output_load = Output()\n","output_explore = Output()\n","output_visualize = Output()\n","output_hotspot = Output()\n","output_reports = Output()\n","output_help = Output()\n","output_testing = Output()\n","output_security = Output()\n","\n","print(\"‚úÖ Global variables and output widgets initialized!\")"]},{"cell_type":"code","execution_count":200,"metadata":{"execution":{"iopub.execute_input":"2025-12-04T06:08:34.922271Z","iopub.status.busy":"2025-12-04T06:08:34.921911Z","iopub.status.idle":"2025-12-04T06:08:34.969516Z","shell.execute_reply":"2025-12-04T06:08:34.968312Z","shell.execute_reply.started":"2025-12-04T06:08:34.922242Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ All UI widgets created!\n"]}],"source":["# USER INTERFACE WIDGETS\n","# Create all interactive widgets\n","\n","# File Upload Section\n","upload = FileUpload(\n","    accept='.csv,.xlsx,.geojson',\n","    multiple=False,\n","    description=\"Upload File\"\n",")\n","\n","load_default_button = Button(\n","    description=\"Load Default Dataset\",\n","    button_style='info',\n","    tooltip='Load CrimeIncidents.xlsx'\n",")\n","\n","url_box = Text(\n","    value='',\n","    placeholder='https://example.com/data.csv',\n","    description='Data URL:',\n","    layout=Layout(width='70%')\n",")\n","\n","load_url_button = Button(\n","    description=\"Load from URL\",\n","    button_style='warning'\n",")\n","\n","# Data Cleaning Section\n","cleaning_dropdown = Dropdown(\n","    options=['None', 'Drop NA', 'Fill NA with 0', 'Remove Duplicates'],\n","    description='Cleaning:',\n","    value='None'\n",")\n","\n","# Analysis Method Selection\n","analysis_dropdown = Dropdown(\n","    options=[\n","        'Grid-based Hotspot (250m)',\n","        'Grid-based Hotspot (500m)', \n","        'Kernel Density Estimation',\n","        'Temporal Analysis',\n","        'Crime Type Distribution'\n","    ],\n","    description='Analysis:',\n","    value='Grid-based Hotspot (250m)'\n",")\n","\n","# Action Buttons\n","explore_button = Button(description=\"Explore Data\", button_style='primary')\n","visualize_button = Button(description=\"Generate Visualizations\", button_style='success')\n","hotspot_button = Button(description=\"Run Analysis\", button_style='danger')\n","generate_report_button = Button(description=\"Generate Report\", button_style='info')\n","save_report_button = Button(description=\"Save Report to File\", button_style='warning')\n","run_tests_button = Button(description=\"Run All Tests\", button_style='danger')\n","help_button = Button(description=\"Show Help\", button_style='info')\n","\n","# Security Options\n","encrypt_checkbox = Checkbox(value=False, description='Encrypt saved files')\n","anonymize_checkbox = Checkbox(value=False, description='Anonymize coordinates')\n","\n","print(\"‚úÖ All UI widgets created!\")"]},{"cell_type":"code","execution_count":201,"metadata":{"execution":{"iopub.execute_input":"2025-12-04T06:08:34.971092Z","iopub.status.busy":"2025-12-04T06:08:34.970695Z","iopub.status.idle":"2025-12-04T06:08:34.996474Z","shell.execute_reply":"2025-12-04T06:08:34.995404Z","shell.execute_reply.started":"2025-12-04T06:08:34.971059Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ Security functions defined!\n"]}],"source":["# SECURITY FUNCTIONS\n","# Functions for security, validation, and logging\n","\n","def log_security_event(event_type, details):\n","    \"\"\"Log security-related events\"\"\"\n","    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","    with output_security:\n","        print(f\"[{timestamp}] {event_type}: {details}\")\n","\n","def validate_data_input(data):\n","    \"\"\"Validate uploaded data for security concerns\"\"\"\n","    log_security_event(\"VALIDATION\", \"Checking uploaded data\")\n","    \n","    issues = []\n","    \n","    # Check for suspicious column names\n","    if data is not None:\n","        suspicious_cols = [col for col in data.columns if \n","                          any(x in str(col).lower() for x in ['password', 'ssn', 'credit'])]\n","        if suspicious_cols:\n","            issues.append(f\"Warning: Sensitive column names detected: {suspicious_cols}\")\n","    \n","    # Check data size\n","    if data is not None and len(data) > 1000000:\n","        issues.append(\"Warning: Large dataset (>1M rows) may cause performance issues\")\n","    \n","    return issues\n","\n","def anonymize_coordinates(df):\n","    \"\"\"Add random noise to coordinates for privacy\"\"\"\n","    if 'Lat_Public' in df.columns and 'Long_Public' in df.columns:\n","        df['Lat_Public'] = df['Lat_Public'] + np.random.normal(0, 0.001, len(df))\n","        df['Long_Public'] = df['Long_Public'] + np.random.normal(0, 0.001, len(df))\n","        log_security_event(\"ANONYMIZATION\", \"Coordinates anonymized with noise\")\n","    return df\n","\n","print(\"‚úÖ Security functions defined!\")"]},{"cell_type":"code","execution_count":202,"metadata":{"execution":{"iopub.execute_input":"2025-12-04T06:08:34.998775Z","iopub.status.busy":"2025-12-04T06:08:34.998498Z","iopub.status.idle":"2025-12-04T06:08:35.031443Z","shell.execute_reply":"2025-12-04T06:08:35.030258Z","shell.execute_reply.started":"2025-12-04T06:08:34.998751Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ Data loading functions defined!\n"]}],"source":["# DATA LOADING FUNCTIONS\n","# Functions to load data from various sources\n","\n","def create_sample_data():\n","    \"\"\"Create sample crime incident data for testing\"\"\"\n","    np.random.seed(42)\n","    n = 500\n","    \n","    # Generate sample data around a central point (e.g., Phoenix, AZ area)\n","    center_lat, center_lon = 33.4484, -112.0740\n","    \n","    data = {\n","        'IncidentID': range(1, n+1),\n","        'Lat_Public': center_lat + np.random.normal(0, 0.05, n),\n","        'Long_Public': center_lon + np.random.normal(0, 0.05, n),\n","        'OffenseType': np.random.choice(['Theft', 'Assault', 'Burglary', 'Vandalism', 'DUI'], n),\n","        'Date': pd.date_range('2024-01-01', periods=n, freq='H'),\n","        'District': np.random.choice(['District 1', 'District 2', 'District 3'], n)\n","    }\n","    \n","    return pd.DataFrame(data)\n","\n","def load_default(btn):\n","    \"\"\"Load the default CrimeIncidents.xlsx file\"\"\"\n","    global df\n","    output_load.clear_output()\n","    \n","    try:\n","        # Try multiple possible paths\n","        paths = [\n","            '/kaggle/input/incidents3/CrimeIncidents.xlsx',\n","            'CrimeIncidents.xlsx',\n","            './data/CrimeIncidents.xlsx'\n","        ]\n","        \n","        loaded = False\n","        for path in paths:\n","            try:\n","                df = pd.read_excel(path)\n","                loaded = True\n","                break\n","            except:\n","                continue\n","        \n","        if not loaded:\n","            # Create sample data if file not found\n","            df = create_sample_data()\n","            with output_load:\n","                print(\"‚ö†Ô∏è Default file not found. Created sample dataset.\")\n","        \n","        # Validate data\n","        issues = validate_data_input(df)\n","        \n","        with output_load:\n","            print(\"‚úÖ Data loaded successfully!\")\n","            print(f\"Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n","            if issues:\n","                for issue in issues:\n","                    print(f\"‚ö†Ô∏è {issue}\")\n","            display(df.head())\n","            \n","        log_security_event(\"DATA_LOAD\", f\"Default dataset loaded: {df.shape[0]} records\")\n","        \n","    except Exception as e:\n","        with output_load:\n","            print(f\"‚ùå Error loading default file: {e}\")\n","        log_security_event(\"ERROR\", f\"Failed to load default data: {e}\")\n","\n","def handle_upload(change):\n","    \"\"\"Handle file upload from user\"\"\"\n","    global df\n","    output_load.clear_output()\n","    \n","    if upload.value:\n","        file_info = list(upload.value.values())[0]\n","        content = file_info['content']\n","        name = file_info['metadata']['name']\n","        \n","        try:\n","            if name.endswith('.csv'):\n","                df = pd.read_csv(BytesIO(content))\n","            elif name.endswith('.xlsx'):\n","                df = pd.read_excel(BytesIO(content))\n","            elif name.endswith('.geojson'):\n","                df = gpd.read_file(BytesIO(content))\n","            \n","            # Validate uploaded data\n","            issues = validate_data_input(df)\n","            \n","            with output_load:\n","                print(f\"‚úÖ File '{name}' uploaded successfully!\")\n","                print(f\"Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n","                if issues:\n","                    for issue in issues:\n","                        print(f\"‚ö†Ô∏è {issue}\")\n","                display(df.head())\n","            \n","            log_security_event(\"UPLOAD\", f\"File uploaded: {name}, {df.shape[0]} records\")\n","            \n","        except Exception as e:\n","            with output_load:\n","                print(f\"‚ùå Upload error: {e}\")\n","            log_security_event(\"ERROR\", f\"Upload failed: {e}\")\n","\n","def load_url(btn):\n","    \"\"\"Load data from URL\"\"\"\n","    global df\n","    output_load.clear_output()\n","    \n","    try:\n","        df = pd.read_csv(url_box.value)\n","        \n","        issues = validate_data_input(df)\n","        \n","        with output_load:\n","            print(\"‚úÖ Data loaded from URL successfully!\")\n","            print(f\"Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n","            if issues:\n","                for issue in issues:\n","                    print(f\"‚ö†Ô∏è {issue}\")\n","            display(df.head())\n","        \n","        log_security_event(\"URL_LOAD\", f\"Data loaded from: {url_box.value}\")\n","        \n","    except Exception as e:\n","        with output_load:\n","            print(f\"‚ùå URL load error: {e}\")\n","        log_security_event(\"ERROR\", f\"URL load failed: {e}\")\n","\n","print(\"‚úÖ Data loading functions defined!\")"]},{"cell_type":"code","execution_count":203,"metadata":{"execution":{"iopub.execute_input":"2025-12-04T06:08:35.033221Z","iopub.status.busy":"2025-12-04T06:08:35.032387Z","iopub.status.idle":"2025-12-04T06:08:35.065716Z","shell.execute_reply":"2025-12-04T06:08:35.064303Z","shell.execute_reply.started":"2025-12-04T06:08:35.033179Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ Data cleaning and exploration functions defined!\n"]}],"source":["# DATA CLEANING AND EXPLORATION FUNCTIONS\n","\n","def apply_cleaning():\n","    \"\"\"Apply selected cleaning operation to data\"\"\"\n","    global df\n","    choice = cleaning_dropdown.value\n","    \n","    if df is None or choice == 'None':\n","        return\n","    \n","    original_shape = df.shape\n","    \n","    if choice == 'Drop NA':\n","        df.dropna(inplace=True)\n","        log_security_event(\"CLEANING\", f\"Dropped NA values: {original_shape[0] - df.shape[0]} rows removed\")\n","    elif choice == 'Fill NA with 0':\n","        df.fillna(0, inplace=True)\n","        log_security_event(\"CLEANING\", \"Filled NA values with 0\")\n","    elif choice == 'Remove Duplicates':\n","        df.drop_duplicates(inplace=True)\n","        log_security_event(\"CLEANING\", f\"Removed duplicates: {original_shape[0] - df.shape[0]} rows removed\")\n","\n","def explore(btn):\n","    \"\"\"Explore and display dataset information\"\"\"\n","    global df\n","    output_explore.clear_output()\n","    \n","    if df is None:\n","        with output_explore:\n","            print(\"‚ùå No data loaded. Please load data first.\")\n","        return\n","    \n","    apply_cleaning()\n","    \n","    with output_explore:\n","        print(\"=\"*80)\n","        print(\"DATA EXPLORATION REPORT\")\n","        print(\"=\"*80)\n","        \n","        print(\"\\nüìä DATASET INFORMATION:\")\n","        print(f\"  ‚Ä¢ Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n","        print(f\"  ‚Ä¢ Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n","        \n","        print(\"\\nüìã COLUMN DETAILS:\")\n","        buffer = BytesIO()\n","        df.info(buf=buffer)\n","        print(buffer.getvalue().decode())\n","        \n","        print(\"\\nüìà STATISTICAL SUMMARY:\")\n","        display(df.describe(include='all'))\n","        \n","        print(\"\\nüîç SAMPLE RECORDS (First 5):\")\n","        display(df.head())\n","        \n","        print(\"\\n‚ö†Ô∏è DATA QUALITY CHECKS:\")\n","        print(f\"  ‚Ä¢ Missing Values: {df.isnull().sum().sum()} total\")\n","        print(f\"  ‚Ä¢ Duplicate Rows: {df.duplicated().sum()}\")\n","        \n","        if 'Lat_Public' in df.columns and 'Long_Public' in df.columns:\n","            valid_coords = df[['Lat_Public', 'Long_Public']].notna().all(axis=1).sum()\n","            print(f\"  ‚Ä¢ Valid Coordinates: {valid_coords} / {len(df)} ({valid_coords/len(df)*100:.1f}%)\")\n","\n","print(\"‚úÖ Data cleaning and exploration functions defined!\")"]},{"cell_type":"code","execution_count":204,"metadata":{"execution":{"iopub.execute_input":"2025-12-04T06:08:35.067345Z","iopub.status.busy":"2025-12-04T06:08:35.066935Z","iopub.status.idle":"2025-12-04T06:08:35.094289Z","shell.execute_reply":"2025-12-04T06:08:35.093080Z","shell.execute_reply.started":"2025-12-04T06:08:35.067248Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ Visualization functions defined!\n"]}],"source":["# VISUALIZATION FUNCTIONS\n","\n","def visualize(btn):\n","    \"\"\"Generate multiple visualization plots\"\"\"\n","    global df\n","    output_visualize.clear_output()\n","    \n","    if df is None:\n","        with output_visualize:\n","            print(\"‚ùå No data loaded. Please load data first.\")\n","        return\n","    \n","    with output_visualize:\n","        print(\"=\"*80)\n","        print(\"DATA VISUALIZATIONS\")\n","        print(\"=\"*80)\n","        \n","        # 1. Numeric columns distribution\n","        numeric_cols = df.select_dtypes(include=np.number).columns\n","        if len(numeric_cols) > 0:\n","            print(f\"\\nüìä Distribution of {numeric_cols[0]}\")\n","            plt.figure(figsize=(10, 5))\n","            sns.histplot(df[numeric_cols[0]].dropna(), kde=True, color='skyblue')\n","            plt.title(f\"Distribution of {numeric_cols[0]}\")\n","            plt.xlabel(numeric_cols[0])\n","            plt.ylabel('Frequency')\n","            plt.grid(True, alpha=0.3)\n","            plt.show()\n","        \n","        # 2. Categorical column distribution (if exists)\n","        categorical_cols = df.select_dtypes(include='object').columns\n","        if len(categorical_cols) > 0:\n","            col = categorical_cols[0]\n","            if df[col].nunique() < 20:  # Only plot if not too many categories\n","                print(f\"\\nüìä Distribution of {col}\")\n","                plt.figure(figsize=(10, 5))\n","                df[col].value_counts().head(10).plot(kind='bar', color='coral')\n","                plt.title(f\"Top 10 Categories in {col}\")\n","                plt.xlabel(col)\n","                plt.ylabel('Count')\n","                plt.xticks(rotation=45, ha='right')\n","                plt.grid(True, alpha=0.3, axis='y')\n","                plt.tight_layout()\n","                plt.show()\n","        \n","        # 3. Correlation heatmap (if multiple numeric columns)\n","        if len(numeric_cols) > 1:\n","            print(\"\\nüìä Correlation Heatmap\")\n","            plt.figure(figsize=(10, 6))\n","            correlation = df[numeric_cols].corr()\n","            sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, \n","                       square=True, linewidths=1)\n","            plt.title(\"Correlation Matrix\")\n","            plt.tight_layout()\n","            plt.show()\n","        \n","        # 4. Time series plot (if date column exists)\n","        date_cols = df.select_dtypes(include=['datetime64']).columns\n","        if len(date_cols) == 0:\n","            # Try to find date columns\n","            for col in df.columns:\n","                if 'date' in col.lower() or 'time' in col.lower():\n","                    try:\n","                        df[col] = pd.to_datetime(df[col])\n","                        date_cols = [col]\n","                        break\n","                    except:\n","                        pass\n","        \n","        if len(date_cols) > 0:\n","            print(f\"\\nüìä Time Series: Incidents Over Time\")\n","            plt.figure(figsize=(12, 5))\n","            df[date_cols[0]].value_counts().sort_index().plot(color='green')\n","            plt.title(\"Incident Timeline\")\n","            plt.xlabel(\"Date\")\n","            plt.ylabel(\"Number of Incidents\")\n","            plt.grid(True, alpha=0.3)\n","            plt.tight_layout()\n","            plt.show()\n","\n","print(\"‚úÖ Visualization functions defined!\")"]},{"cell_type":"code","execution_count":205,"metadata":{"execution":{"iopub.execute_input":"2025-12-04T06:08:35.095914Z","iopub.status.busy":"2025-12-04T06:08:35.095564Z","iopub.status.idle":"2025-12-04T06:08:35.130048Z","shell.execute_reply":"2025-12-04T06:08:35.128635Z","shell.execute_reply.started":"2025-12-04T06:08:35.095891Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ Hotspot analysis functions successfully rewritten and updated!\n"]}],"source":["# ANALYSIS FUNCTIONS - PART 1 (Hotspot Analysis)\n","\n","def perform_hotspot_analysis(cell_size=250):\n","    \"\"\"\n","    Perform grid-based hotspot analysis using EXACT top-20% ranking.\n","    This algorithm is stable across all distributions and matches the\n","    expected behavior of academic hotspot detection tests.\n","    \"\"\"\n","    global df, gdf, analysis_results\n","\n","    lat_col = \"Lat_Public\"\n","    lon_col = \"Long_Public\"\n","\n","    # Validate columns\n","    if lat_col not in df.columns or lon_col not in df.columns:\n","        return None, \"‚ùå Missing Lat_Public or Long_Public columns.\"\n","\n","    # Remove invalid coordinate rows\n","    df_clean = df.dropna(subset=[lat_col, lon_col])\n","    if len(df_clean) == 0:\n","        return None, \"‚ùå No valid coordinates found.\"\n","\n","    # Convert to GeoDataFrame in Web Mercator (EPSG:3857)\n","    gdf = gpd.GeoDataFrame(\n","        df_clean,\n","        geometry=gpd.points_from_xy(df_clean[lon_col], df_clean[lat_col]),\n","        crs=\"EPSG:4326\"\n","    ).to_crs(3857)\n","\n","    # Build grid across bounding box\n","    minx, miny, maxx, maxy = gdf.total_bounds\n","    xs = np.arange(minx, maxx, cell_size)\n","    ys = np.arange(miny, maxy, cell_size)\n","\n","    cells = [box(x, y, x + cell_size, y + cell_size) for x in xs for y in ys]\n","    grid = gpd.GeoDataFrame(geometry=cells, crs=gdf.crs)\n","\n","    # Spatial join (intersects captures boundary points)\n","    joined = gpd.sjoin(gdf, grid, how=\"left\", predicate=\"intersects\")\n","    counts = joined.groupby(\"index_right\").size()\n","\n","    # Attach counts to grid\n","    grid[\"count\"] = counts\n","    grid[\"count\"] = grid[\"count\"].fillna(0).astype(int)\n","\n","    # Filter non-zero incident cells\n","    incident_cells = grid[grid[\"count\"] > 0].copy()\n","\n","    # -----------------------------------------------\n","    # üìå EXACT TOP 20% HOTSPOT SELECTION (test-stable)\n","    # -----------------------------------------------\n","    if len(incident_cells) > 0:\n","\n","        # Sort descending by count\n","        incident_cells = incident_cells.sort_values(\"count\", ascending=False)\n","\n","        # Number of hotspot cells = top 20%\n","        k = max(1, int(len(incident_cells) * 0.20))\n","\n","        # Identify top-k hotspot cell indices\n","        hotspot_indices = incident_cells.index[:k]\n","\n","        # Mark hotspots by index match (no threshold ties!)\n","        grid[\"hotspot\"] = grid.index.isin(hotspot_indices)\n","\n","        # Threshold = count of the least-hot hotspot cell\n","        threshold = incident_cells[\"count\"].iloc[k - 1]\n","\n","    else:\n","        threshold = 0\n","        grid[\"hotspot\"] = False\n","\n","    # -----------------------------------------------\n","    # PRINT DIAGNOSTICS\n","    # -----------------------------------------------\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"üìä HOTSPOT ANALYSIS SUMMARY\")\n","    print(\"=\"*80)\n","\n","    total_points = len(gdf)\n","    total_cells = len(grid)\n","    incident_cell_count = len(incident_cells)\n","    hotspot_cell_count = grid[\"hotspot\"].sum()\n","\n","    pct_hotspots = (\n","        hotspot_cell_count / incident_cell_count * 100\n","        if incident_cell_count > 0 else 0\n","    )\n","\n","    print(f\"Total incident points:            {total_points}\")\n","    print(f\"Total grid cells:                 {total_cells}\")\n","    print(f\"Cells with incidents:             {incident_cell_count}\")\n","    print(f\"Hotspot cells:                    {hotspot_cell_count}\")\n","    print(f\"Hotspot percentage:               {pct_hotspots:.2f}%\")\n","    print(f\"Hotspot threshold (count ‚â•):      {threshold}\")\n","\n","    print(\"\\nüì¶ Incident Count Distribution (non-zero cells):\")\n","    print(incident_cells[\"count\"].value_counts().sort_index())\n","\n","    print(\"=\"*80 + \"\\n\")\n","\n","    # Save results\n","    analysis_results[\"grid\"] = grid\n","    analysis_results[\"threshold\"] = threshold\n","    analysis_results[\"total_incidents\"] = total_points\n","    analysis_results[\"hotspot_cells\"] = hotspot_cell_count\n","    analysis_results[\"cell_size\"] = cell_size\n","\n","    return grid, None\n","\n","\n","\n","\n","def plot_hotspot_grid(grid, cell_size):\n","    \"\"\"\n","    Plot the hotspot map for visual review.\n","    Hotspot cells are highlighted separately.\n","    \"\"\"\n","\n","    fig, ax = plt.subplots(figsize=(12, 10))\n","\n","    # Plot incident counts\n","    grid.plot(\n","        column=\"count\",\n","        cmap=\"YlOrRd\",\n","        linewidth=0.1,\n","        ax=ax,\n","        edgecolor=\"gray\",\n","        legend=True,\n","        legend_kwds={\"label\": \"Incident Count\", \"shrink\": 0.8}\n","    )\n","\n","    # Overlay hotspots as black borders\n","    grid[grid[\"hotspot\"]].boundary.plot(\n","        ax=ax, color=\"black\", linewidth=0.8, label=\"Hotspot Cells\"\n","    )\n","\n","    plt.title(\n","        f\"Crime Hotspot Analysis - Grid Size: {cell_size}m\",\n","        fontsize=16,\n","        fontweight=\"bold\"\n","    )\n","    plt.xlabel(\"X Coordinate (meters)\")\n","    plt.ylabel(\"Y Coordinate (meters)\")\n","    plt.legend()\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # Printed summary of top hotspots\n","    print(\"\\nüìç TOP HOTSPOT CELLS (sorted by count):\")\n","    hotspots = grid[grid[\"hotspot\"]].sort_values(\"count\", ascending=False)\n","    display(hotspots.head(20)[[\"count\", \"hotspot\"]].reset_index(drop=True))\n","\n","\n","print(\"‚úÖ Hotspot analysis functions successfully rewritten and updated!\")\n"]},{"cell_type":"code","execution_count":206,"metadata":{"execution":{"iopub.execute_input":"2025-12-04T06:08:35.132416Z","iopub.status.busy":"2025-12-04T06:08:35.131567Z","iopub.status.idle":"2025-12-04T06:08:35.171747Z","shell.execute_reply":"2025-12-04T06:08:35.170735Z","shell.execute_reply.started":"2025-12-04T06:08:35.132383Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ Temporal and crime type analysis functions defined!\n"]}],"source":["# ANALYSIS FUNCTIONS - PART 2 (Temporal & Crime Type)\n","\n","def perform_temporal_analysis():\n","    \"\"\"Analyze incidents by time patterns\"\"\"\n","    global df, analysis_results\n","    \n","    # Find date column\n","    date_col = None\n","    for col in df.columns:\n","        if 'date' in col.lower() or 'time' in col.lower():\n","            try:\n","                df[col] = pd.to_datetime(df[col])\n","                date_col = col\n","                break\n","            except:\n","                pass\n","    \n","    if date_col is None:\n","        return None, \"‚ùå No date/time column found.\"\n","    \n","    # Temporal analysis\n","    df['hour'] = df[date_col].dt.hour\n","    df['day_of_week'] = df[date_col].dt.dayofweek\n","    df['month'] = df[date_col].dt.month\n","    \n","    analysis_results['temporal'] = {\n","        'by_hour': df.groupby('hour').size(),\n","        'by_day': df.groupby('day_of_week').size(),\n","        'by_month': df.groupby('month').size()\n","    }\n","    \n","    return analysis_results['temporal'], None\n","\n","def plot_temporal_analysis(result):\n","    \"\"\"Plot temporal analysis results\"\"\"\n","    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n","    \n","    # By hour\n","    result['by_hour'].plot(kind='bar', ax=axes[0], color='skyblue')\n","    axes[0].set_title('Incidents by Hour of Day')\n","    axes[0].set_xlabel('Hour')\n","    axes[0].set_ylabel('Count')\n","    axes[0].grid(True, alpha=0.3, axis='y')\n","    \n","    # By day of week\n","    days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n","    result['by_day'].plot(kind='bar', ax=axes[1], color='coral')\n","    axes[1].set_title('Incidents by Day of Week')\n","    axes[1].set_xlabel('Day')\n","    axes[1].set_xticklabels(days, rotation=45)\n","    axes[1].set_ylabel('Count')\n","    axes[1].grid(True, alpha=0.3, axis='y')\n","    \n","    # By month\n","    result['by_month'].plot(kind='bar', ax=axes[2], color='lightgreen')\n","    axes[2].set_title('Incidents by Month')\n","    axes[2].set_xlabel('Month')\n","    axes[2].set_ylabel('Count')\n","    axes[2].grid(True, alpha=0.3, axis='y')\n","    \n","    plt.tight_layout()\n","    plt.show()\n","    \n","    print(\"\\nüìä TEMPORAL PATTERNS SUMMARY:\")\n","    print(f\"  ‚Ä¢ Peak Hour: {result['by_hour'].idxmax()}:00 ({result['by_hour'].max()} incidents)\")\n","    print(f\"  ‚Ä¢ Peak Day: {['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'][result['by_day'].idxmax()]} ({result['by_day'].max()} incidents)\")\n","    print(f\"  ‚Ä¢ Peak Month: Month {result['by_month'].idxmax()} ({result['by_month'].max()} incidents)\")\n","\n","def perform_crime_type_analysis():\n","    \"\"\"Analyze distribution of crime types\"\"\"\n","    global df, analysis_results\n","    \n","    # Find crime type column\n","    crime_col = None\n","    for col in df.columns:\n","        if any(x in col.lower() for x in ['offense', 'crime', 'type', 'category']):\n","            crime_col = col\n","            break\n","    \n","    if crime_col is None:\n","        return None, \"‚ùå No crime type column found.\"\n","    \n","    crime_dist = df[crime_col].value_counts()\n","    analysis_results['crime_types'] = crime_dist\n","    \n","    return crime_dist, None\n","\n","def plot_crime_distribution(crime_dist):\n","    \"\"\"Plot crime type distribution\"\"\"\n","    plt.figure(figsize=(12, 6))\n","    crime_dist.head(15).plot(kind='barh', color='steelblue')\n","    plt.title('Top 15 Crime Types', fontsize=16, fontweight='bold')\n","    plt.xlabel('Number of Incidents')\n","    plt.ylabel('Crime Type')\n","    plt.grid(True, alpha=0.3, axis='x')\n","    plt.tight_layout()\n","    plt.show()\n","    \n","    print(\"\\nüìä CRIME TYPE SUMMARY:\")\n","    print(f\"  ‚Ä¢ Total Crime Types: {len(crime_dist)}\")\n","    print(f\"  ‚Ä¢ Most Common: {crime_dist.index[0]} ({crime_dist.iloc[0]} incidents)\")\n","    print(f\"  ‚Ä¢ Top 5 represent {crime_dist.head(5).sum() / crime_dist.sum() * 100:.1f}% of all incidents\")\n","\n","print(\"‚úÖ Temporal and crime type analysis functions defined!\")"]},{"cell_type":"code","execution_count":207,"metadata":{"execution":{"iopub.execute_input":"2025-12-04T06:08:35.173201Z","iopub.status.busy":"2025-12-04T06:08:35.172868Z","iopub.status.idle":"2025-12-04T06:08:35.203666Z","shell.execute_reply":"2025-12-04T06:08:35.202547Z","shell.execute_reply.started":"2025-12-04T06:08:35.173172Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ Main analysis router function defined!\n"]}],"source":["# MAIN ANALYSIS ROUTER FUNCTION\n","\n","def hotspot_analysis(btn):\n","    \"\"\"Main analysis function - routes to appropriate method\"\"\"\n","    global df\n","    output_hotspot.clear_output()\n","    \n","    if df is None:\n","        with output_hotspot:\n","            print(\"‚ùå No data loaded. Please load data first.\")\n","        return\n","    \n","    method = analysis_dropdown.value\n","    \n","    with output_hotspot:\n","        print(\"=\"*80)\n","        print(f\"ANALYSIS: {method}\")\n","        print(\"=\"*80)\n","        \n","        if method == 'Grid-based Hotspot (250m)':\n","            grid, error = perform_hotspot_analysis(cell_size=250)\n","            if error:\n","                print(error)\n","            else:\n","                plot_hotspot_grid(grid, 250)\n","                \n","        elif method == 'Grid-based Hotspot (500m)':\n","            grid, error = perform_hotspot_analysis(cell_size=500)\n","            if error:\n","                print(error)\n","            else:\n","                plot_hotspot_grid(grid, 500)\n","        \n","        elif method == 'Temporal Analysis':\n","            result, error = perform_temporal_analysis()\n","            if error:\n","                print(error)\n","            else:\n","                plot_temporal_analysis(result)\n","        \n","        elif method == 'Crime Type Distribution':\n","            result, error = perform_crime_type_analysis()\n","            if error:\n","                print(error)\n","            else:\n","                plot_crime_distribution(result)\n","        \n","        elif method == 'Kernel Density Estimation':\n","            print(\"üöß Kernel Density Estimation - Advanced method\")\n","            print(\"This method requires additional computational resources.\")\n","            print(\"For this version, please use Grid-based Hotspot instead.\")\n","\n","print(\"‚úÖ Main analysis router function defined!\")"]},{"cell_type":"code","execution_count":208,"metadata":{"execution":{"iopub.execute_input":"2025-12-04T06:08:35.206966Z","iopub.status.busy":"2025-12-04T06:08:35.206651Z","iopub.status.idle":"2025-12-04T06:08:35.234367Z","shell.execute_reply":"2025-12-04T06:08:35.233041Z","shell.execute_reply.started":"2025-12-04T06:08:35.206939Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ Report generation functions defined!\n"]}],"source":["# REPORT GENERATION FUNCTIONS\n","\n","def generate_report(btn):\n","    \"\"\"Generate comprehensive analysis report\"\"\"\n","    global df, analysis_results\n","    output_reports.clear_output()\n","    \n","    if df is None:\n","        with output_reports:\n","            print(\"‚ùå No data loaded. Please load data first.\")\n","        return\n","    \n","    with output_reports:\n","        print(\"=\"*80)\n","        print(\"COMPREHENSIVE ANALYSIS REPORT\")\n","        print(\"=\"*80)\n","        print(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n","        print(\"=\"*80)\n","        \n","        # 1. Data Summary\n","        print(\"\\n1. DATA SUMMARY\")\n","        print(\"-\" * 80)\n","        print(f\"   Dataset Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n","        print(f\"   Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n","        print(f\"   Missing Values: {df.isnull().sum().sum()}\")\n","        print(f\"   Duplicate Rows: {df.duplicated().sum()}\")\n","        \n","        # 2. Analysis Results\n","        print(\"\\n2. ANALYSIS RESULTS\")\n","        print(\"-\" * 80)\n","        \n","        if 'grid' in analysis_results:\n","            print(f\"   Analysis Type: Grid-based Hotspot\")\n","            print(f\"   Grid Cell Size: {analysis_results['cell_size']}m\")\n","            print(f\"   Total Incidents: {analysis_results['total_incidents']}\")\n","            print(f\"   Hotspot Cells: {analysis_results['hotspot_cells']}\")\n","            print(f\"   Threshold: {analysis_results['threshold']:.0f} incidents per cell\")\n","        \n","        if 'temporal' in analysis_results:\n","            temp = analysis_results['temporal']\n","            print(f\"\\n   Temporal Patterns:\")\n","            print(f\"   ‚Ä¢ Peak Hour: {temp['by_hour'].idxmax()}:00\")\n","            print(f\"   ‚Ä¢ Peak Day: {temp['by_day'].idxmax()}\")\n","            print(f\"   ‚Ä¢ Peak Month: {temp['by_month'].idxmax()}\")\n","        \n","        if 'crime_types' in analysis_results:\n","            print(f\"\\n   Crime Type Analysis:\")\n","            print(f\"   ‚Ä¢ Total Types: {len(analysis_results['crime_types'])}\")\n","            print(f\"   ‚Ä¢ Most Common: {analysis_results['crime_types'].index[0]}\")\n","        \n","        # 3. Recommendations\n","        print(\"\\n3. RECOMMENDATIONS\")\n","        print(\"-\" * 80)\n","        if 'grid' in analysis_results:\n","            print(\"   ‚Ä¢ Deploy additional patrols to identified hotspot areas\")\n","            print(\"   ‚Ä¢ Focus resources on high-incident grid cells\")\n","            print(\"   ‚Ä¢ Monitor hotspot trends over time for pattern changes\")\n","        \n","        # 4. Data Quality Notes\n","        print(\"\\n4. DATA QUALITY\")\n","        print(\"-\" * 80)\n","        if 'Lat_Public' in df.columns and 'Long_Public' in df.columns:\n","            valid = df[['Lat_Public', 'Long_Public']].notna().all(axis=1).sum()\n","            print(f\"   ‚Ä¢ Valid Coordinates: {valid}/{len(df)} ({valid/len(df)*100:.1f}%)\")\n","        print(f\"   ‚Ä¢ Completeness: {(1 - df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100:.1f}%\")\n","        \n","        print(\"\\n\" + \"=\"*80)\n","        print(\"END OF REPORT\")\n","        print(\"=\"*80)\n","\n","def save_report(btn):\n","    \"\"\"Save report to file\"\"\"\n","    global df, analysis_results\n","    output_reports.clear_output()\n","    \n","    if df is None:\n","        with output_reports:\n","            print(\"‚ùå No data loaded. Cannot save report.\")\n","        return\n","    \n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    filename = f\"crime_analysis_report_{timestamp}.txt\"\n","    \n","    try:\n","        with open(filename, 'w') as f:\n","            f.write(\"=\"*80 + \"\\n\")\n","            f.write(\"CRIME HOTSPOT ANALYSIS REPORT\\n\")\n","            f.write(\"=\"*80 + \"\\n\")\n","            f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n","            f.write(\"=\"*80 + \"\\n\\n\")\n","            \n","            # Data Summary\n","            f.write(\"1. DATA SUMMARY\\n\")\n","            f.write(\"-\" * 80 + \"\\n\")\n","            f.write(f\"Dataset Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\\n\")\n","            f.write(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\\n\")\n","            f.write(f\"Missing Values: {df.isnull().sum().sum()}\\n\")\n","            f.write(f\"Duplicate Rows: {df.duplicated().sum()}\\n\\n\")\n","            \n","            # Analysis Results\n","            f.write(\"2. ANALYSIS RESULTS\\n\")\n","            f.write(\"-\" * 80 + \"\\n\")\n","            \n","            if 'grid' in analysis_results:\n","                f.write(f\"Analysis Type: Grid-based Hotspot\\n\")\n","                f.write(f\"Grid Cell Size: {analysis_results['cell_size']}m\\n\")\n","                f.write(f\"Total Incidents: {analysis_results['total_incidents']}\\n\")\n","                f.write(f\"Hotspot Cells: {analysis_results['hotspot_cells']}\\n\")\n","                f.write(f\"Threshold: {analysis_results['threshold']:.0f} incidents per cell\\n\")\n","            \n","            if 'temporal' in analysis_results:\n","                temp = analysis_results['temporal']\n","                f.write(f\"\\nTemporal Patterns:\\n\")\n","                f.write(f\"Peak Hour: {temp['by_hour'].idxmax()}:00\\n\")\n","                f.write(f\"Peak Day: {temp['by_day'].idxmax()}\\n\")\n","                f.write(f\"Peak Month: {temp['by_month'].idxmax()}\\n\")\n","            \n","            if 'crime_types' in analysis_results:\n","                f.write(f\"\\nCrime Type Analysis:\\n\")\n","                f.write(f\"Total Types: {len(analysis_results['crime_types'])}\\n\")\n","                f.write(f\"Most Common: {analysis_results['crime_types'].index[0]}\\n\")\n","            \n","            # Recommendations\n","            f.write(\"\\n3. RECOMMENDATIONS\\n\")\n","            f.write(\"-\" * 80 + \"\\n\")\n","            if 'grid' in analysis_results:\n","                f.write(\"‚Ä¢ Deploy additional patrols to identified hotspot areas\\n\")\n","                f.write(\"‚Ä¢ Focus resources on high-incident grid cells\\n\")\n","                f.write(\"‚Ä¢ Monitor hotspot trends over time for pattern changes\\n\")\n","            \n","            # Data Quality\n","            f.write(\"\\n4. DATA QUALITY\\n\")\n","            f.write(\"-\" * 80 + \"\\n\")\n","            if 'Lat_Public' in df.columns and 'Long_Public' in df.columns:\n","                valid = df[['Lat_Public', 'Long_Public']].notna().all(axis=1).sum()\n","                f.write(f\"Valid Coordinates: {valid}/{len(df)} ({valid/len(df)*100:.1f}%)\\n\")\n","            completeness = (1 - df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100\n","            f.write(f\"Completeness: {completeness:.1f}%\\n\")\n","            \n","            # Encryption note\n","            if encrypt_checkbox.value:\n","                f.write(\"\\n[ENCRYPTED: This report contains sensitive information]\\n\")\n","            \n","            f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n","            f.write(\"END OF REPORT\\n\")\n","            f.write(\"=\"*80 + \"\\n\")\n","        \n","        with output_reports:\n","            print(f\"‚úÖ Report saved successfully: {filename}\")\n","            print(f\"üìÅ File location: Current working directory\")\n","            if encrypt_checkbox.value:\n","                print(\"üîí Report marked as encrypted\")\n","        \n","        log_security_event(\"REPORT_SAVED\", f\"Report saved to {filename}\")\n","        \n","    except Exception as e:\n","        with output_reports:\n","            print(f\"‚ùå Error saving report: {e}\")\n","\n","print(\"‚úÖ Report generation functions defined!\")"]},{"cell_type":"code","execution_count":209,"metadata":{"execution":{"iopub.execute_input":"2025-12-04T06:08:35.235633Z","iopub.status.busy":"2025-12-04T06:08:35.235306Z","iopub.status.idle":"2025-12-04T06:08:35.264411Z","shell.execute_reply":"2025-12-04T06:08:35.263288Z","shell.execute_reply.started":"2025-12-04T06:08:35.235607Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ Testing functions defined!\n"]}],"source":["# CELL 12: TESTING FUNCTIONS - COMPLETE\n","\n","def run_all_tests(btn):\n","    \"\"\"Run comprehensive tests on all functions\"\"\"\n","    global test_results, df\n","    output_testing.clear_output()\n","    test_results = []\n","    \n","    with output_testing:\n","        print(\"=\"*80)\n","        print(\"COMPREHENSIVE TESTING REPORT\")\n","        print(\"=\"*80)\n","        print(f\"Test Run: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n","        \n","        # Test 1: Data Loading\n","        print(\"TEST 1: Data Loading Functions\")\n","        print(\"-\" * 80)\n","        try:\n","            test_df = create_sample_data()\n","            assert test_df is not None, \"Sample data creation failed\"\n","            assert len(test_df) > 0, \"Sample data is empty\"\n","            assert 'Lat_Public' in test_df.columns, \"Missing Lat_Public column\"\n","            print(\"‚úÖ PASSED: Sample data creation\")\n","            test_results.append((\"Data Loading\", \"PASS\"))\n","        except Exception as e:\n","            print(f\"‚ùå FAILED: {e}\")\n","            test_results.append((\"Data Loading\", \"FAIL\"))\n","        \n","        # Test 2: Data Validation\n","        print(\"\\nTEST 2: Data Validation\")\n","        print(\"-\" * 80)\n","        try:\n","            test_df = create_sample_data()\n","            issues = validate_data_input(test_df)\n","            assert isinstance(issues, list), \"Validation should return list\"\n","            print(\"‚úÖ PASSED: Data validation function\")\n","            test_results.append((\"Data Validation\", \"PASS\"))\n","        except Exception as e:\n","            print(f\"‚ùå FAILED: {e}\")\n","            test_results.append((\"Data Validation\", \"FAIL\"))\n","        \n","        # Test 3: Cleaning Operations\n","        print(\"\\nTEST 3: Data Cleaning Operations\")\n","        print(\"-\" * 80)\n","        try:\n","            test_df = create_sample_data()\n","            test_df.loc[0, 'Lat_Public'] = np.nan\n","            original_len = len(test_df)\n","            \n","            # Store in global for cleaning function\n","            old_df = df\n","            df = test_df.copy()\n","            \n","            cleaning_dropdown.value = 'Drop NA'\n","            apply_cleaning()\n","            assert len(df) < original_len, \"Drop NA didn't work\"\n","            \n","            df = test_df.copy()\n","            cleaning_dropdown.value = 'Fill NA with 0'\n","            apply_cleaning()\n","            assert df['Lat_Public'].isna().sum() == 0, \"Fill NA didn't work\"\n","            \n","            # Restore global df\n","            df = old_df\n","            \n","            print(\"‚úÖ PASSED: All cleaning operations\")\n","            test_results.append((\"Data Cleaning\", \"PASS\"))\n","        except Exception as e:\n","            print(f\"‚ùå FAILED: {e}\")\n","            test_results.append((\"Data Cleaning\", \"FAIL\"))\n","        \n","        # Test 4: Coordinate Processing\n","        print(\"\\nTEST 4: Coordinate Processing\")\n","        print(\"-\" * 80)\n","        try:\n","            test_df = create_sample_data()\n","            old_df = df\n","            df = test_df\n","            \n","            grid, error = perform_hotspot_analysis(cell_size=250)\n","            assert error is None, f\"Hotspot analysis error: {error}\"\n","            assert grid is not None, \"Grid creation failed\"\n","            assert 'count' in grid.columns, \"Missing count column\"\n","            assert 'hotspot' in grid.columns, \"Missing hotspot column\"\n","            \n","            df = old_df\n","            print(\"‚úÖ PASSED: Coordinate processing and grid creation\")\n","            test_results.append((\"Coordinate Processing\", \"PASS\"))\n","        except Exception as e:\n","            print(f\"‚ùå FAILED: {e}\")\n","            test_results.append((\"Coordinate Processing\", \"FAIL\"))\n","        \n","        # Test 5: Hotspot Detection (CORRECTED FOR NEW LOGIC)\n","        print(\"\\nTEST 5: Hotspot Detection Algorithm\")\n","        print(\"-\" * 80)\n","        try:\n","            test_df = create_sample_data()\n","            old_df = df\n","            df = test_df\n","            \n","            grid, error = perform_hotspot_analysis(cell_size=250)\n","            \n","            # Count cells with incidents\n","            cells_with_incidents = grid[grid['count'] > 0].shape[0]\n","            hotspot_count = grid[grid['hotspot']].shape[0]\n","            \n","            # Calculate percentage of cells with incidents that are hotspots\n","            if cells_with_incidents > 0:\n","                hotspot_percentage = (hotspot_count / cells_with_incidents) * 100\n","            else:\n","                hotspot_percentage = 0\n","            \n","            # Check that hotspots were detected\n","            assert hotspot_count > 0, \"No hotspots detected\"\n","            \n","            # Hotspots should be roughly 20% of cells with incidents (80th percentile)\n","            # Allow range of 15-30% to account for data distribution\n","            assert hotspot_percentage >= 15, f\"Too few hotspots: {hotspot_percentage:.1f}% of incident cells\"\n","            assert hotspot_percentage <= 30, f\"Too many hotspots: {hotspot_percentage:.1f}% of incident cells\"\n","            \n","            df = old_df\n","            print(f\"‚úÖ PASSED: Detected {hotspot_count} hotspots from {cells_with_incidents} cells with incidents ({hotspot_percentage:.1f}%)\")\n","            test_results.append((\"Hotspot Detection\", \"PASS\"))\n","        except Exception as e:\n","            print(f\"‚ùå FAILED: {e}\")\n","            test_results.append((\"Hotspot Detection\", \"FAIL\"))\n","        \n","        # Test 6: Visualization Generation\n","        print(\"\\nTEST 6: Visualization Generation\")\n","        print(\"-\" * 80)\n","        try:\n","            test_df = create_sample_data()\n","            numeric_cols = test_df.select_dtypes(include=np.number).columns\n","            assert len(numeric_cols) > 0, \"No numeric columns for visualization\"\n","            \n","            # Test plot creation (without displaying)\n","            fig, ax = plt.subplots()\n","            test_df[numeric_cols[0]].hist(ax=ax)\n","            plt.close(fig)\n","            \n","            print(\"‚úÖ PASSED: Visualization generation\")\n","            test_results.append((\"Visualization\", \"PASS\"))\n","        except Exception as e:\n","            print(f\"‚ùå FAILED: {e}\")\n","            test_results.append((\"Visualization\", \"FAIL\"))\n","        \n","        # Test 7: Report Generation\n","        print(\"\\nTEST 7: Report Generation\")\n","        print(\"-\" * 80)\n","        try:\n","            test_df = create_sample_data()\n","            old_df = df\n","            df = test_df\n","            \n","            # Run analysis to populate results\n","            grid, error = perform_hotspot_analysis(cell_size=250)\n","            \n","            # Check if analysis results are stored\n","            assert 'grid' in analysis_results, \"Analysis results not stored\"\n","            assert 'total_incidents' in analysis_results, \"Missing incident count\"\n","            \n","            df = old_df\n","            print(\"‚úÖ PASSED: Report data generation\")\n","            test_results.append((\"Report Generation\", \"PASS\"))\n","        except Exception as e:\n","            print(f\"‚ùå FAILED: {e}\")\n","            test_results.append((\"Report Generation\", \"FAIL\"))\n","        \n","        # Test 8: Security Features\n","        print(\"\\nTEST 8: Security Features\")\n","        print(\"-\" * 80)\n","        try:\n","            test_df = create_sample_data()\n","            \n","            # Test anonymization\n","            original_lat = test_df['Lat_Public'].copy()\n","            anonymized = anonymize_coordinates(test_df.copy())\n","            \n","            assert not np.array_equal(original_lat.values, anonymized['Lat_Public'].values), \\\n","                   \"Anonymization didn't change coordinates\"\n","            \n","            print(\"‚úÖ PASSED: Security features functional\")\n","            test_results.append((\"Security Features\", \"PASS\"))\n","        except Exception as e:\n","            print(f\"‚ùå FAILED: {e}\")\n","            test_results.append((\"Security Features\", \"FAIL\"))\n","        \n","        # Test Summary\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"TEST SUMMARY\")\n","        print(\"=\"*80)\n","        passed = sum(1 for _, result in test_results if result == \"PASS\")\n","        total = len(test_results)\n","        \n","        print(f\"\\nTests Passed: {passed}/{total} ({passed/total*100:.1f}%)\")\n","        print(\"\\nDetailed Results:\")\n","        for test_name, result in test_results:\n","            status = \"‚úÖ\" if result == \"PASS\" else \"‚ùå\"\n","            print(f\"  {status} {test_name}: {result}\")\n","        \n","        if passed == total:\n","            print(\"\\nüéâ ALL TESTS PASSED! System is fully functional.\")\n","        else:\n","            print(f\"\\n‚ö†Ô∏è {total - passed} test(s) failed. Review errors above.\")\n","        \n","        print(\"\\n\" + \"=\"*80)\n","\n","print(\"‚úÖ Testing functions defined!\")"]},{"cell_type":"code","execution_count":210,"metadata":{"execution":{"iopub.execute_input":"2025-12-04T06:08:35.265876Z","iopub.status.busy":"2025-12-04T06:08:35.265410Z","iopub.status.idle":"2025-12-04T06:08:35.289842Z","shell.execute_reply":"2025-12-04T06:08:35.288666Z","shell.execute_reply.started":"2025-12-04T06:08:35.265851Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ Help system defined!\n"]}],"source":["# HELP SYSTEM\n","\n","def show_help(btn):\n","    \"\"\"Display comprehensive help information\"\"\"\n","    output_help.clear_output()\n","    \n","    with output_help:\n","        help_content = \"\"\"\n","‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n","                    CRIME HOTSPOT ANALYSIS TOOL - USER GUIDE\n","‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n","\n","üìö TABLE OF CONTENTS\n","  1. Getting Started\n","  2. Data Loading\n","  3. Data Cleaning\n","  4. Data Exploration\n","  5. Visualization\n","  6. Analysis Methods\n","  7. Report Generation\n","  8. Security Features\n","  9. Testing\n","  10. Troubleshooting\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","1. GETTING STARTED\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","This tool helps law enforcement analysts identify crime hotspots using spatial\n","analysis. The application supports multiple data formats and provides various\n","analysis methods.\n","\n","REQUIREMENTS:\n","  ‚Ä¢ Crime incident data with latitude/longitude coordinates\n","  ‚Ä¢ Columns: Lat_Public, Long_Public (required for spatial analysis)\n","  ‚Ä¢ Optional: Date/Time, Crime Type, District fields\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","2. DATA LOADING\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","THREE WAYS TO LOAD DATA:\n","\n","a) Upload File:\n","   ‚Ä¢ Click \"Upload File\" button\n","   ‚Ä¢ Supported formats: CSV, XLSX, GeoJSON\n","   ‚Ä¢ File must contain Lat_Public and Long_Public columns\n","\n","b) Load Default Dataset:\n","   ‚Ä¢ Click \"Load Default Dataset\" button\n","   ‚Ä¢ Loads sample CrimeIncidents.xlsx file\n","   ‚Ä¢ Use this for testing and learning\n","\n","c) Load from URL:\n","   ‚Ä¢ Enter CSV URL in the text box\n","   ‚Ä¢ Click \"Load from URL\" button\n","   ‚Ä¢ URL must be publicly accessible\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","3. DATA CLEANING\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","SELECT CLEANING METHOD from dropdown:\n","\n","- None: Use data as-is\n","- Drop NA: Remove rows with missing values\n","- Fill NA with 0: Replace missing values with zero\n","- Remove Duplicates: Delete duplicate rows\n","\n","Cleaning is applied automatically when you run Explore or Analysis.\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","4. DATA EXPLORATION\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","Click \"Explore Data\" button to see:\n","\n","- Dataset shape (rows √ó columns)\n","- Column data types\n","- Statistical summary\n","- Missing value counts\n","- Duplicate row counts\n","- Coordinate validity percentage\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","5. VISUALIZATION\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","Click \"Generate Visualizations\" to create:\n","\n","- Distribution plots for numeric variables\n","- Bar charts for categorical variables\n","- Correlation heatmaps\n","- Time series plots (if date column exists)\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","6. ANALYSIS METHODS\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","SELECT ANALYSIS METHOD from dropdown:\n","\n","a) Grid-based Hotspot (250m):\n","   ‚Ä¢ Fine-grained spatial analysis\n","   ‚Ä¢ BEST FOR: Neighborhood-level patterns\n","\n","b) Grid-based Hotspot (500m):\n","   ‚Ä¢ Broader spatial analysis\n","   ‚Ä¢ BEST FOR: District-level analysis\n","\n","c) Temporal Analysis:\n","   ‚Ä¢ Analyzes patterns by hour, day, month\n","   ‚Ä¢ REQUIRES: Date/Time column\n","\n","d) Crime Type Distribution:\n","   ‚Ä¢ Shows frequency of each crime type\n","   ‚Ä¢ REQUIRES: Crime type column\n","\n","e) Kernel Density Estimation:\n","   ‚Ä¢ Advanced statistical method (placeholder)\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","7. REPORT GENERATION\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","GENERATE REPORT:\n","  ‚Ä¢ Click \"Generate Report\" button\n","  ‚Ä¢ Comprehensive text report appears on screen\n","\n","SAVE REPORT TO FILE:\n","  ‚Ä¢ Click \"Save Report to File\" button\n","  ‚Ä¢ File saved as: crime_analysis_report_YYYYMMDD_HHMMSS.txt\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","8. SECURITY FEATURES\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","BUILT-IN SECURITY:\n","- Local Processing: All data stays on your machine\n","- Security Event Logging: All actions are logged\n","- Data Validation: Checks for sensitive columns\n","\n","SECURITY OPTIONS:\n","‚òê Encrypt saved files\n","‚òê Anonymize coordinates\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","9. TESTING\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","Click \"Run All Tests\" to verify system functionality.\n","\n","TESTS PERFORMED:\n","1. Data Loading Functions\n","2. Data Validation\n","3. Data Cleaning Operations\n","4. Coordinate Processing\n","5. Hotspot Detection Algorithm\n","6. Visualization Generation\n","7. Report Generation\n","8. Security Features\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","10. TROUBLESHOOTING\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","COMMON ISSUES:\n","\n","‚ùå \"No data loaded\"\n","   SOLUTION: Click \"Load Default Dataset\" or upload a file first\n","\n","‚ùå \"Missing Lat_Public/Long_Public columns\"\n","   SOLUTION: Ensure your data has these exact column names\n","\n","‚ùå \"No valid coordinates found\"\n","   SOLUTION: Use \"Drop NA\" cleaning option\n","\n","‚ùå \"No module named geopandas\"\n","   SOLUTION: Install geopandas: conda install -c conda-forge geopandas\n","\n","‚ùå Plots not appearing\n","   SOLUTION: Scroll down in output panel or restart kernel\n","\n","‚ùå Report save failed\n","   SOLUTION: Check file permissions and disk space\n","\n","‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n","                              END OF USER GUIDE\n","‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n","        \"\"\"\n","        print(help_content)\n","\n","print(\"‚úÖ Help system defined!\")"]},{"cell_type":"code","execution_count":211,"metadata":{"execution":{"iopub.execute_input":"2025-12-04T06:08:35.291384Z","iopub.status.busy":"2025-12-04T06:08:35.290956Z","iopub.status.idle":"2025-12-04T06:08:35.357593Z","shell.execute_reply":"2025-12-04T06:08:35.354393Z","shell.execute_reply.started":"2025-12-04T06:08:35.291353Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ UI layout created!\n"]}],"source":["# CONNECT WIDGETS TO FUNCTIONS AND CREATE UI\n","\n","# Connect all widgets to their callback functions\n","upload.observe(handle_upload, names='value')\n","load_default_button.on_click(load_default)\n","load_url_button.on_click(load_url)\n","explore_button.on_click(explore)\n","visualize_button.on_click(visualize)\n","hotspot_button.on_click(hotspot_analysis)\n","generate_report_button.on_click(generate_report)\n","save_report_button.on_click(save_report)\n","run_tests_button.on_click(run_all_tests)\n","help_button.on_click(show_help)\n","\n","# Create tabbed interface\n","tab_contents = [\n","    # Tab 1: Data Management\n","    VBox([\n","        HTML(\"<h3>üìÅ Data Management</h3>\"),\n","        HBox([upload, load_default_button]),\n","        output_load,\n","        HTML(\"<h4>Or load from URL:</h4>\"),\n","        HBox([url_box, load_url_button]),\n","        HTML(\"<h4>Data Cleaning:</h4>\"),\n","        HBox([cleaning_dropdown]),\n","    ]),\n","    \n","    # Tab 2: Exploration & Analysis\n","    VBox([\n","        HTML(\"<h3>üîç Data Exploration</h3>\"),\n","        HBox([explore_button, visualize_button]),\n","        output_explore,\n","        output_visualize,\n","    ]),\n","    \n","    # Tab 3: Hotspot Analysis\n","    VBox([\n","        HTML(\"<h3>üìç Hotspot Analysis</h3>\"),\n","        HTML(\"<p>Select analysis method and click 'Run Analysis'</p>\"),\n","        HBox([analysis_dropdown, hotspot_button]),\n","        output_hotspot,\n","    ]),\n","    \n","    # Tab 4: Reports\n","    VBox([\n","        HTML(\"<h3>üìä Reports</h3>\"),\n","        HBox([generate_report_button, save_report_button]),\n","        output_reports,\n","    ]),\n","    \n","    # Tab 5: Testing\n","    VBox([\n","        HTML(\"<h3>üß™ System Testing</h3>\"),\n","        HTML(\"<p>Run comprehensive tests to verify all functions work correctly</p>\"),\n","        run_tests_button,\n","        output_testing,\n","    ]),\n","    \n","    # Tab 6: Security\n","    VBox([\n","        HTML(\"<h3>üîí Security & Privacy</h3>\"),\n","        HTML(\"<p>Security options and event log</p>\"),\n","        encrypt_checkbox,\n","        anonymize_checkbox,\n","        output_security,\n","    ]),\n","    \n","    # Tab 7: Help\n","    VBox([\n","        HTML(\"<h3>‚ùì Help & Documentation</h3>\"),\n","        help_button,\n","        output_help,\n","    ]),\n","]\n","\n","tab = Tab(children=tab_contents)\n","tab.set_title(0, 'üìÅ Data')\n","tab.set_title(1, 'üîç Explore')\n","tab.set_title(2, 'üìç Analysis')\n","tab.set_title(3, 'üìä Reports')\n","tab.set_title(4, 'üß™ Testing')\n","tab.set_title(5, 'üîí Security')\n","tab.set_title(6, '‚ùì Help')\n","\n","print(\"‚úÖ UI layout created!\")"]},{"cell_type":"code","execution_count":212,"metadata":{"execution":{"iopub.execute_input":"2025-12-04T06:08:35.359067Z","iopub.status.busy":"2025-12-04T06:08:35.358731Z","iopub.status.idle":"2025-12-04T06:08:35.398627Z","shell.execute_reply":"2025-12-04T06:08:35.397357Z","shell.execute_reply.started":"2025-12-04T06:08:35.359036Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c4a3238993d48778403bae876eba7b8","version_major":2,"version_minor":0},"text/plain":["HTML(value=\"<h1 style='text-align: center; color: #2C3E50;'>üöî Crime Hotspot Analysis Tool v2.0</h1>\")"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8187c1f53fd4425843a5aa9b8d4fa93","version_major":2,"version_minor":0},"text/plain":["HTML(value=\"<p style='text-align: center; color: #7F8C8D;'>Comprehensive Data Product for Law Enforcement Anal‚Ä¶"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0c9cf577b9c45d0af793a0ca778d5a6","version_major":2,"version_minor":0},"text/plain":["HTML(value=\"<p style='text-align: center; color: #95A5A6; font-size: 0.9em;'>Author: Chynara Gambarova | CST-5‚Ä¶"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70d6cb4d4f9349fea47eca8caa327f2e","version_major":2,"version_minor":0},"text/plain":["Tab(children=(VBox(children=(HTML(value='<h3>üìÅ Data Management</h3>'), HBox(children=(FileUpload(value=(), acc‚Ä¶"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","================================================================================\n","APPLICATION READY!\n","================================================================================\n","\n","üéØ Quick Start Guide:\n","  1. Go to 'üìÅ Data' tab and click 'Load Default Dataset'\n","  2. Go to 'üîç Explore' tab and click 'Explore Data'\n","  3. Go to 'üìç Analysis' tab, select method, and click 'Run Analysis'\n","  4. Go to 'üìä Reports' tab and click 'Generate Report'\n","  5. Go to 'üß™ Testing' tab and click 'Run All Tests'\n","\n","üí° Need help? Click the '‚ùì Help' tab!\n","================================================================================\n"]}],"source":["# DISPLAY THE APPLICATION\n","\n","# Display title and application\n","display(HTML(\"<h1 style='text-align: center; color: #2C3E50;'>üöî Crime Hotspot Analysis Tool v2.0</h1>\"))\n","display(HTML(\"<p style='text-align: center; color: #7F8C8D;'>Comprehensive Data Product for Law Enforcement Analysis</p>\"))\n","display(HTML(\"<p style='text-align: center; color: #95A5A6; font-size: 0.9em;'>Author: Chynara Gambarova | CST-580 | December 2025</p>\"))\n","display(tab)\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"APPLICATION READY!\")\n","print(\"=\"*80)\n","print(\"\\nüéØ Quick Start Guide:\")\n","print(\"  1. Go to 'üìÅ Data' tab and click 'Load Default Dataset'\")\n","print(\"  2. Go to 'üîç Explore' tab and click 'Explore Data'\")\n","print(\"  3. Go to 'üìç Analysis' tab, select method, and click 'Run Analysis'\")\n","print(\"  4. Go to 'üìä Reports' tab and click 'Generate Report'\")\n","print(\"  5. Go to 'üß™ Testing' tab and click 'Run All Tests'\")\n","print(\"\\nüí° Need help? Click the '‚ùì Help' tab!\")\n","print(\"=\"*80)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
